---
title: "Analyzing handwritten documents with handwriter"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{handwriter-writership-analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE
)
```

```{r setup, echo = FALSE}
library(handwriter)
```

## Overview

-Reference Amy's papers 
-Explain the scenario: questioned document(s) and a closed set of writers
-Estimates posterior probability of writership for each questioned document and each writer in the closed set
-We will use example documents included in the handwriter package
-Explain that processing handwriting produces *graphs*.

## Getting Started
Choose a directory on your computer to store the files that handwriter produces. This directory will eventually store:

1. Processed handwriting documents for creating a cluster template and training a Bayesian hierarchical. It will also store the processed questioned document(s).
2. Cluster template(s)
3. A Bayesian hierarcical model fit to the processed model training documents
4. Writership analysis of the questioned document(s).

```{r}
main_dir <- "/Users/stephanie/Documents/CSAFE_example_data"

# create the directory if it doesn't already exist
if(!dir.exists(main_dir)){dir.create(main_dir)}
```

## Create a clustering template
**TO DO: Summarize the training docs**

We will use the example template training documents included in the handwriter package. Get the file path to these documents.
```{r}
template_images_dir <- system.file("extdata/example_images/template_training_images", 
                                   package = "handwriter")
```

Process the template training documents to transform the handwriting into graphs. Output the processed graphs to main_dir > data > template_graphs. The function will create this directory automatically, and the [`make_clustering_templates`] function will look for the template training graphs here. 
```{r}
# process the handwriting
process_batch_dir(image_batch = template_images_dir,
                  batch_output_dir = file.path(main_dir, "data", "template_graphs"),
                  transform_output = 'document')
```

Create a cluster template with `K=10` clusters. Choose the number of cores you would like to use with `num_dist_cores`. The input `max_iters` determines how many iterations the K-means algorithm could perform. In practice, we recommend using at least 20 iterations. Here will will use `max_iters=3` in interest of speed. Again, in interest of speed for this example we will only use 1000 graphs for creating the cluster template. In practice, use `num_graphs = 'All'` to use all available training graphs. Choose a starting seed. These seed determines the starting cluster centers for the K-means algorithm. Because we are randomly selecting 1000 graphs, rerunning this function with the same seed will use the same starting cluster centers but will likely have a different sample of 1000 graphs so the end result would be a different cluster template. Choose the number of cluster templates to create with `num_runs`. If the starting seed is 100 and `num_runs=3` then cluster templates will be created with seeds 100, 101, and 102. 
```{r}
template_list <- make_clustering_templates(template_dir = main_dir,
                                           K = 10,
                                           num_dist_cores = 2,
                                           max_iters = 3,
                                           num_graphs = 1000,
                                           starting_seed = 100,
                                           num_runs = 1)
```

**TO DO**

- **Report outlier ratio**
- **Implement template quality measure**

## Fit a Bayesian Hierarchical Model
**TO DO: 

- **Summarize the training docs**
- **add reference to Amy's paper**
- **Discuss model - mention that priors assume each writer in closed set is equally likely**

The next step is to fit a Bayesian hierarchical model. We will use the model training handwriting documents included in handwriter. Get the file path to these documents.
```{r}
model_images_dir <- system.file("extdata/example_images/model_training_images", 
                                package = "handwriter")
```

Process the model training documents to transform the handwriting into graphs. Output the processed graphs to main_dir > data > model_graphs. The function will create this directory automatically.
```{r}
# process the handwriting
process_batch_dir(image_batch = model_images_dir,
                  batch_output_dir = file.path(main_dir, "data", "model_graphs"),
                  transform_output = 'document')
```
  
Use the cluster template to assign the processed model training graphs to the nearest cluster. `template_list` is a list of templates so we access the first (and only in this case) template with `template_list[[1]]`.
```{r}  
model_clusters <- get_clusterassignment(clustertemplate = template_list[[1]],
                                        input_dir = file.path(main_dir, "data", "model_graphs"))
```

Format the model training data for the hierarchical model. The writer IDs are recorded in the model training documents' filenames in characters 2-5. The remainder of the filename can be use as the document name to distinguish between multiple documents from the same writer. The 6th character is an underscore, so we choose to omit it here.

**TO DO: Explain model parameters**
```{r}
model_data <- format_model_data(model_proc_list=model_clusters, 
                                writer_indices=c(2,5), 
                                doc_indices=c(7,18), 
                                a=2, b=0.25, c=2, d=2, e=0.5)
```

Now that the model training data has been properly formatted, we can fit the model. The `fit_model` function 
is a wrapped for `rjags::jags.model`. The RJAGS model that we use is 
```{r comment='', echo=FALSE}
cat(readLines("model_wrapped_cauchy.txt"), sep = '\n')
```

We fit the model with 4000 MCMC iterations. Then we drop the first 1000 as burn-in.
```{r}
draws <- fit_model(model_data$rjags_data, num_iters = 4000)
draws <- drop_burnin(draws, 1000)
```

## Analyze Questioned Documents
We will use the "questioned" documents included in handwriter. In this case, we know the ground truth of who wrote each document so we will be able to measure the accuracy. Get the file path to these documents.
```{r}
questioned_images_dir <- system.file("extdata/example_images/questioned_images", 
                                     package = "handwriter")
```

Process the questioned documents to transform the handwriting into graphs. Output the processed graphs to main_dir > data > questioned_graphs. The function will create this directory automatically.
```{r}
process_batch_dir(image_batch = questioned_images_dir,
                  batch_output_dir = file.path(main_dir, "data", "questioned_graphs"),
                  transform_output = 'document')
```

Use the cluster template to assign the processed questioned graphs to the nearest cluster. Again, `template_list` is a list of templates so we access the first (and only in this case) template with `template_list[[1]]`.
```{r}
questioned_clusters <- get_clusterassignment(clustertemplate = template_list[[1]], 
                                             input_dir = file.path(main_dir, "data", "questioned_graphs"))
```

Format the questioned data so that we can use it with the fitted model. As with the model documents, the write ID is contained in characters 2-5 of the filename and we use the remainder of the file name, minus the underscore in the 6th character, as the document name in case a writer has multiple documents. In practice, we would not know the writer of a questioned document so we would assign a unique identifier at the beginning of the document's filename.
```{r}
questioned_data <- format_questioned_data(formatted_model_data = model_data,
                                          questioned_proc_list = questioned_clusters,
                                          writer_indices=c(2,5), 
                                          doc_indices=c(7,18))
```

**TO DO**

- **add cluster fill count plots**
- **add outlier ratio**

Use the fitted model to estimate the posterior probability of writership.
```{r}
analysis <- analyze_questioned_documents(model_training_data = model_data, 
                                         draws = draws, 
                                         questioned_data = questioned_data, 
                                         num_cores = 2)
```

Plot the posterior probabilities of writership.
```{r out.width="100%", fig.cap="Posterior probabilities of writership."}
plot_posterior_probabilities(analysis)
```

