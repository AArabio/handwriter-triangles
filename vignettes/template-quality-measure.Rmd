---
title: "template-quality-measure"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{template-quality-measure}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(handwriter)
library(ggplot2)
library(dendextend)
```

## Template data
```{r}
# load template
all_templates <- readRDS("~/Documents/CSAFE_template_quality_measure/template_seed100/data/all_templates.rds")
template <- all_templates[[1]]
rm(all_templates)
```

Plot cluster fill counts for template writers.
```{r}
template_data <- format_template_data(template)
plot_cluster_fill_counts(template_data, facet=TRUE)
```

## Evalute hierarchical model on template
```{r}
main_dir <- "/users/stephanie/Documents/CSAFE_template_quality_measure"

# fit model
model_proc_list <- process_batch_dir(input_dir = file.path(main_dir, "data", "model_images"),
                                     output_dir = file.path(main_dir, "data", "model_graphs"))

model_clusters <- get_clusterassignment(clustertemplate = template,
                                        input_dir = file.path(main_dir, "data", "model_graphs"))

model_data <- format_model_data(model_proc_list = model_clusters,
                                writer_indices = c(2,5),
                                doc_indices = c(7,18))

model <- fit_model(model_data = model_data,
                   num_iters = 100,
                   num_chains = 1)

# analyze questioned documents
questioned_proc_list <- process_batch_dir(input_dir = file.path(main_dir, "data", "questioned_images"),
                                          output_dir = file.path(main_dir, "data", "questioned_graphs"))

questioned_clusters <- get_clusterassignment(clustertemplate = template,
                                             input_dir = file.path(main_dir, "data", "questioned_graphs"))

questioned_data <- format_questioned_data(formatted_model_data = model_data,
                                          questioned_proc_list = questioned_clusters,
                                          writer_indices = c(2,5),
                                          doc_indices = c(7,18))
analysis <- analyze_questioned_documents(model_data = model_data,
                                         model = model,
                                         questioned_data = questioned_data,
                                         num_cores = 5)
analysis$posterior_probabilities
```


## Hierarchical clustering
### Wrangle data
```{r}
df <- data.frame(writer = template$writers, doc = template$docnames, cluster = template$cluster, stringsAsFactors = FALSE)

# count graphs per cluster per document
df <- df %>% dplyr::group_by(writer, doc, cluster) %>% dplyr::summarize(count = dplyr::n())

# make a column for each cluster
df <- df %>% tidyr::pivot_wider(names_from = cluster, values_from = count, values_fill = 0)

# convert to matrix and use docnames as rownames
docnames <- df$doc
M <- df %>% dplyr::ungroup() %>% dplyr::select(-writer, -doc)
M <- as.matrix(M)
rownames(M) <- docnames
```

## Apply hierarchical clustering
```{r}
# calculate distances between all pairs of documents
D <- dist(df[,3:ncol(df)], method = "manhattan")

# cluster
hc <- hclust(D)

# plot
plot(hc)

# evaluate
cluster_cut <- cutree(hc, k=10)
table(cluster_cut, df$writer)
```

### Try normalizing the data
```{r}
# normalize
standardize <- function(x){
  x <- (x - min(x))/(max(x) - min(x))
  return(x)
}

X <- apply(df[,3:ncol(df)], 2, function(x) standardize(x))

# calculate distances between all pairs of documents
D <- dist(X)

# cluster
hc <- hclust(D)

# plot
plot(hc)

# evaluate
cluster_cut <- cutree(hc, k=10)
table(cluster_cut, df$writer)
```


## Multi-class LDA
### Example with Iris Dataset
```{r}
library(caret)
data(iris)

set.seed(123)
indexes <- caret::createDataPartition(iris$Species, p = .75, list = FALSE)
train <- iris[indexes, ]
test <- iris[-indexes, ]

trCtrl <- trainControl(method = "cv", number = 5, verboseIter = TRUE)
fit_car <- train(Species~., data=train, method="lda", trControl = trCtrl, metric = "Accuracy")

pred_car <- predict(fit_car, test[,-5])
data.frame(original = test$Species, pred = pred_car)
```
```{r}
set.seed(123)

# drop doc column, outlier cluster (constant within-in group), first cluster (constant within-in group)
lda_template <- template_data$cluster_fill_counts[,-c(2, 3, 4)]

# add index row
lda_template <- cbind(index = 1:nrow(lda_template), lda_template)

# change writer to factor (otherwise caret tries to perform regression)
lda_template <- lda_template %>% dplyr::mutate(writer = factor(writer))

# split train and test sets
train_indx <- lda_template %>% 
  dplyr::group_by(writer) %>% 
  dplyr::slice_sample(n=2)  %>% 
  dplyr::pull(index)
train <- lda_template[train_indx, ]
test <- lda_template[-train_indx, ]

# drop index column
train <- train[,-1]
test <- test[,-1]

# # check correlation between variables
# cordf <- cor(train[,-1])
# caret::findCorrelation(cordf, verbose = TRUE)

fit_car <- caret::train(writer~., data=train, method="lda")

pred_car <- predict(fit_car, test[,-1])
data.frame(original = test$writer, pred = pred_car)
```

